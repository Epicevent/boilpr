import streamlit as st
import uuid
import time
import pandas as pd

# -----------------------------
# (ì˜ˆì‹œ) Ground Truth JSON (ë°ëª¨ìš©)
# -----------------------------
GROUND_TRUTH = {
  "queries": [
    {
      "query": "ì–‘ì‚° ì´ì‚¬ì—…ë¹„ í˜‘ì˜ ì–¸ì œ ì´ë£¨ì–´ì§€ë‚˜ìš”?",
      "content": [
        {
            "chunk_id": "1.22.3",
            "chunk_type": "paragraph",
            "metadata_text": "ã€Œë°©ìœ„ì‚¬ì—…ê´€ë¦¬ê·œì •ã€ 22ì¡°3í•­",
            "content": "í†µí•©ì‚¬ì—…ê´€ë¦¬íŒ€ì¥ì€ ì œ2í•­ì— ë”°ë¥¸ ì–‘ì‚° ì´ì‚¬ì—…ë¹„ ì‹¬ì¸µê²€í†  ê²°ê³¼ë¥¼ ê·¼ê±°ë¡œ ê¸°íšì¬ì •ë¶€ì¥ê´€ì—ê²Œ ì–‘ì‚° ì˜ˆì‚° ë° ì´ì‚¬ì—…ë¹„ í˜‘ì˜ ë“±ì„ ìš”êµ¬í•  ìˆ˜ ìˆë‹¤."
        },
        {
            "chunk_id": "1.22",
            "chunk_type": "article",
            "metadata_text": "ã€Œë°©ìœ„ì‚¬ì—…ê´€ë¦¬ê·œì •ã€ 22ì¡°ì˜2 (ì–‘ì‚° ì´ì‚¬ì—…ë¹„ ì‹¬ì¸µê²€í† )",
            "content": "í†µí•©ì‚¬ì—…ê´€ë¦¬íŒ€ì¥ì€ ã€Œêµ­ë°©ì‚¬ì—… ì´ì‚¬ì—…ë¹„ ê´€ë¦¬ì§€ì¹¨ã€ì— ë”°ë¼ ì—°êµ¬ê°œë°œ ì‚¬ì—… íƒ€ë‹¹ì„±ì¡°ì‚¬ë¥¼ í†µí•´ ì¶”ì •í•œ ì–‘ì‚° ì´ì‚¬ì—…ë¹„ì˜ ë³€ë™ì—¬ë¶€ ë“±ì„ ì„¸ë¶€ì ìœ¼ë¡œ ê²€í† í•˜ê¸° ìœ„í•´ ì ì •ì „íˆ¬ìš©ì í•© ë˜ëŠ” ê°œë°œ ì‹œí—˜í‰ê°€ ê²°ê³¼ ê¸°ì¤€ì´ì¡± íŒì •ì„ ë°›ì€ ì´í›„ì— ë°©ìœ„ì‚¬ì—…ì •ì±…êµ­ì¥ì—ê²Œ ì–‘ì‚° ì´ì‚¬ì—…ë¹„ ì‹¬ì¸µê²€í†  ìš”ì²­ì„ ì˜ë¢°í•  ìˆ˜ ìˆë‹¤.  ë°©ìœ„ì‚¬ì—…ì •ì±…êµ­ì¥ì€ ì œ1í•­ì— ë”°ë¼ ì–‘ì‚° ì´ì‚¬ì—…ë¹„ ì‹¬ì¸µê²€í†  ìš”ì²­ì„ ì˜ë¢°ë°›ì€ ê²½ìš° í•œêµ­êµ­ë°©ì—°êµ¬ì› ë“± ì „ë¬¸ì—° êµ¬ê¸°ê´€ì— ë¶„ì„ì„ ì˜ë¢°í•˜ì—¬ì•¼ í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ í†µí•©ì‚¬ì—…ê´€ë¦¬íŒ€ì¥ì—ê²Œ í†µë³´í•œë‹¤.  í†µí•©ì‚¬ì—…ê´€ë¦¬íŒ€ì¥ì€ ì œ2í•­ì— ë”°ë¥¸ ì–‘ì‚° ì´ì‚¬ì—…ë¹„ ì‹¬ì¸µê²€í†  ê²°ê³¼ë¥¼ ê·¼ê±°ë¡œ ê¸°íšì¬ì •ë¶€ì¥ê´€ì—ê²Œ ì–‘ì‚° ì˜ˆì‚° ë° ì´ì‚¬ì—…ë¹„ í˜‘ì˜ ë“±ì„ ìš”êµ¬í•  ìˆ˜ ìˆë‹¤."
        }
      ]
    },
    {
      "query": "ì˜ˆì‚°í¸ì„±ìë£Œ ì œì¶œ ì‹œì ì€ ì–¸ì œì¸ê°€ìš”?",
      "content": [
        {
            "chunk_id": "1.23.2",
            "chunk_type": "paragraph",
            "metadata_text": "ã€Œë°©ìœ„ì‚¬ì—…ê´€ë¦¬ê·œì •ã€ 23ì¡°2í•­",
            "content": "êµ­ê³¼ì—°ì€ êµ­ë°©ì¤‘ê¸°ê³„íšê³¼ êµ­ë°©ë¶€ ì˜ˆì‚°í¸ì„±ì§€ì¹¨ì„ ê·¼ê±°ë¡œ êµ­ê³¼ì—°ì£¼ê´€ ë¬´ê¸°ì²´ê³„ ë° í•µì‹¬ê¸°ìˆ  ì—°êµ¬ê°œë°œì‚¬ì—…ê³¼ ì—°êµ¬ì§€ì›ë¶„ì•¼ ë“±ì— ëŒ€í•œ ì˜ˆì‚°í¸ì„±ìë£Œë¥¼ ì‘ì„±í•˜ì—¬ ì‚¬ì—…ë³¸ë¶€ ë° êµ­ë°©ê¸°ìˆ ë³´í˜¸êµ­ì— ê°ê° ì œì¶œí•œë‹¤."
        },
        {
            "chunk_id": "1.23.3",
            "chunk_type": "paragraph",
            "metadata_text": "ã€Œë°©ìœ„ì‚¬ì—…ê´€ë¦¬ê·œì •ã€ 23ì¡°3í•­",
            "content": "ê¸°í’ˆì›ì€ ì˜ ì œ71ì¡°ì œ2í•­ì— ë”°ë¼ í•¨ì • ë¬´ê¸°ì²´ê³„ ì—°êµ¬ê°œë°œì˜ í’ˆì§ˆë³´ì¦ê³¼ í˜•ìƒê´€ë¦¬ ê¸°ìˆ ì§€ì› ë“±ì— ëŒ€í•œ ì˜ˆì‚°í¸ ì„±ìë£Œë¥¼ ì‘ì„±í•˜ì—¬ ì‚¬ì—…ë³¸ë¶€ì— ì œì¶œí•œë‹¤."
        }
      ]
    },

  ]
}

# -----------------------------
# ê°„ë‹¨í•œ ê²€ìƒ‰ í•¨ìˆ˜ (ë°ëª¨ìš©)
# -----------------------------
def get_ground_truth_results(user_query: str):
    """
    user_queryì™€ GROUND_TRUTH['queries'] ë‚´ queryê°€
    'ì™„ì „íˆ ë™ì¼'í•  ë•Œë§Œ í•´ë‹¹ contentë¥¼ ë°˜í™˜í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ í•¨ìˆ˜.
    """
    matched_contents = []
    for item in GROUND_TRUTH["queries"]:
        if user_query.strip() == item["query"]:
            for c in item["content"]:
                # chunk_id, content í•©ì³ì„œ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´ êµ¬ì„±
                matched_contents.append(
                    f"**Chunk {c['metadata_text']}**\n\n{c['content']}"
                )
    return matched_contents


# -----------------------------
# App Configuration
# -----------------------------
st.set_page_config(page_title="ğŸ“„ğŸ” RAG System Prototype", layout="wide")
st.title("ğŸ“„ğŸ” RAG System Prototype")

# -----------------------------
# Initialize Session State
# -----------------------------
if "uploaded_documents" not in st.session_state:
    st.session_state["uploaded_documents"] = []

if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = str(uuid.uuid4())

if "query_results" not in st.session_state:
    st.session_state["query_results"] = []

# -----------------------------
# Sidebar: Settings
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    with st.expander("ğŸ”¤ Translation & Embedding Methods", expanded=True):
        translate_methods = ["Easy", "Mbart50", "MarianMT", "T5", "Pegasus", "Google Translate"]
        embedding_methods = ["SBERT", "BERT", "FastText", "GPT-3", "Word2Vec"]
        
        col1, col2 = st.columns(2)
        with col1:
            selected_translate = st.selectbox("Select Translation Method", translate_methods, index=0)
        with col2:
            selected_embedding = st.selectbox("Select Embedding Method", embedding_methods, index=0)
    
    with st.expander("ğŸ“ˆ Query Parameters", expanded=True):
        top_k = st.slider("Number of Results (Top K)", min_value=1, max_value=10, value=5)
    
    if st.button("ğŸ§¹ Clear All Data"):
        st.session_state.clear()
        st.success("Session state cleared!")
        st.rerun()

# -----------------------------
# Document Upload Section
# -----------------------------
st.header("ğŸ“„ Document Upload")

upload_col1, upload_col2 = st.columns([3, 1])

with upload_col1:
    uploaded_files = st.file_uploader(
        "Upload your documents (PDF/TXT)",
        accept_multiple_files=True,
        key=st.session_state["uploader_key"]
    )

with upload_col2:
    st.write("")
    st.write("")
    st.markdown(" ", unsafe_allow_html=True)
    st.markdown(" ", unsafe_allow_html=True)
    if st.button("ğŸ“¥ Upload"):
        if uploaded_files:
            new_files = False
            for uploaded_file in uploaded_files:
                file_info = {
                    "id": str(uuid.uuid4()),
                    "name": uploaded_file.name,
                    "size": len(uploaded_file.getvalue()),
                    "type": uploaded_file.type,
                    "data": uploaded_file.getvalue()
                }
                # Prevent duplicates based on file name
                if not any(doc["name"] == uploaded_file.name for doc in st.session_state["uploaded_documents"]):
                    st.session_state["uploaded_documents"].append(file_info)
                    new_files = True
            if new_files:
                st.success("Documents uploaded successfully!")
            else:
                st.info("No new documents to upload.")
        else:
            st.warning("No files selected.")
        
        # Reset the uploader
        st.session_state["uploader_key"] = str(uuid.uuid4())
        st.rerun()

# -----------------------------
# Display Uploaded Documents
# -----------------------------
if st.session_state["uploaded_documents"]:
    st.subheader("ğŸ—‚ï¸ Uploaded Documents")
    
    search_query = st.text_input("ğŸ” Search Documents:")
    if search_query:
        filtered_docs = [doc for doc in st.session_state["uploaded_documents"] 
                         if search_query.lower() in doc["name"].lower()]
    else:
        filtered_docs = st.session_state["uploaded_documents"]
    
    if filtered_docs:
        doc_df = pd.DataFrame([{
            "Name": doc["name"],
            "Size (KB)": f"{doc['size'] / 1024:.2f}",
            "Type": doc["type"]
        } for doc in filtered_docs])
        st.table(doc_df)
        
        selected_docs_to_delete = st.multiselect("Select documents to delete:", [doc["name"] for doc in filtered_docs])
        
        if st.button("ğŸ—‘ï¸ Delete Selected Documents"):
            st.session_state["uploaded_documents"] = [
                doc for doc in st.session_state["uploaded_documents"]
                if doc["name"] not in selected_docs_to_delete
            ]
            st.success("Selected documents deleted!")
            st.rerun()
    else:
        st.info("No documents match your search.")

# -----------------------------
# Query Input Section
# -----------------------------
st.header("ğŸ” Query Input")

query_col1, query_col2 = st.columns([3, 1])

with query_col1:
    query = st.text_input("Enter your query:")

with query_col2:
    st.write("")
    st.markdown(" ", unsafe_allow_html=True)
    submit_query = st.button("ğŸ” Submit Query")

if submit_query and query:
    with st.spinner("Processing your query..."):
        time.sleep(2)  # ê°€ìƒì˜ ì²˜ë¦¬ ì§€ì—°
        
        # (1) Ground Truth ê¸°ë°˜ ë°ëª¨ ê²€ìƒ‰
        ground_truth_matches = get_ground_truth_results(query)
        
        # (2) ê²°ê³¼ êµ¬ì„±
        if ground_truth_matches:
            # ground_truth_matchesê°€ ìˆëŠ” ê²½ìš° â†’ í•´ë‹¹ ê²°ê³¼ë¥¼ ì„¸ì…˜ì— ì €ì¥
            # ì—¬ê¸°ì„œëŠ” top_k ì œí•œ (ìŠ¬ë¼ì´ë”)ë„ ê±¸ì–´ë³¸ë‹¤
            sliced_results = ground_truth_matches[:top_k]
            st.session_state["query_results"] = sliced_results
        else:
            # Ground Truthì— ì—†ì„ ë•ŒëŠ” 'No match found'ë¼ê³ ë§Œ í‘œì‹œ
            st.session_state["query_results"] = ["No match found in Ground Truth."]
    
    st.success("Query processed!")
    
# -----------------------------
# Display Query Results
# -----------------------------
if st.session_state["query_results"]:
    st.subheader("ğŸ“„ Query Results")
    for i, result in enumerate(st.session_state["query_results"]):
        with st.expander(f"Result {i+1}"):
            st.markdown(result)

# -----------------------------
# Footer
# -----------------------------
st.markdown("---")
st.markdown("ğŸ‘¨â€ğŸ’» Built with [Streamlit](https://streamlit.io/) for RAG System Prototyping.")